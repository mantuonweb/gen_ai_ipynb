{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.1.6)\n",
      "Requirement already satisfied: langchain-community in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.1.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.13.2)\n",
      "Requirement already satisfied: pypdf in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (6.5.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.2.1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-chains (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain-chains\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Install required packages\n",
    "%pip install langchain langchain-openai langchain-community langchain-text-splitters faiss-cpu pypdf python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a7b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Successfully created 4 sample text documents!\n",
      "\n",
      "Files created in 'documents' folder:\n",
      "1. python_basics.txt\n",
      "2. ai_intro.txt\n",
      "3. company_policy.txt\n",
      "4. product_info.txt\n",
      "\n",
      "Total files: 4\n",
      "  - company_policy.txt (439 bytes)\n",
      "  - python_basics.txt (404 bytes)\n",
      "  - product_info.txt (275 bytes)\n",
      "  - ai_intro.txt (402 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Create sample text documents\n",
    "import os\n",
    "\n",
    "# Create documents folder if it doesn't exist\n",
    "os.makedirs(\"documents\", exist_ok=True)\n",
    "\n",
    "# Sample TXT file 1 - Python Basics\n",
    "with open(\"documents/python_basics.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"Python Programming Basics\n",
    "\n",
    "Python is a high-level programming language. It was created by Guido van Rossum in 1991.\n",
    "Python is known for its simple syntax and readability. It uses indentation to define code blocks.\n",
    "Popular uses include web development, data science, and automation.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and read\n",
    "- Large standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\"\"\")\n",
    "\n",
    "# Sample TXT file 2 - AI Introduction\n",
    "with open(\"documents/ai_intro.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"Introduction to Artificial Intelligence\n",
    "\n",
    "AI is the simulation of human intelligence by machines. Machine learning is a subset of AI.\n",
    "Deep learning uses neural networks with multiple layers.\n",
    "\n",
    "Common AI Applications:\n",
    "- Chatbots and virtual assistants\n",
    "- Image and speech recognition\n",
    "- Recommendation systems\n",
    "- Autonomous vehicles\n",
    "\n",
    "AI has transformed industries like healthcare, finance, and entertainment.\"\"\")\n",
    "\n",
    "# Sample TXT file 3 - Company Policy\n",
    "with open(\"documents/company_policy.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"Company Remote Work Policy\n",
    "\n",
    "Effective Date: January 2024\n",
    "\n",
    "Remote Work Guidelines:\n",
    "- Employees can work remotely up to 3 days per week\n",
    "- Core hours are 10 AM to 3 PM local time\n",
    "- All team meetings must be scheduled during core hours\n",
    "- Use Slack for daily communication\n",
    "- Submit timesheets every Friday by 5 PM\n",
    "\n",
    "Equipment:\n",
    "- Company provides laptop and monitor\n",
    "- Internet stipend of $50 per month\n",
    "\n",
    "Contact HR for questions about this policy.\"\"\")\n",
    "\n",
    "# Sample TXT file 4 - Product Info\n",
    "with open(\"documents/product_info.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"Product Information - SmartWatch Pro\n",
    "\n",
    "Price: $299\n",
    "Release Date: March 2024\n",
    "\n",
    "Features:\n",
    "- Heart rate monitoring\n",
    "- GPS tracking\n",
    "- 7-day battery life\n",
    "- Water resistant up to 50 meters\n",
    "- Compatible with iOS and Android\n",
    "\n",
    "Warranty: 2 years\n",
    "Colors available: Black, Silver, Rose Gold\"\"\")\n",
    "\n",
    "print(\"‚úì Successfully created 4 sample text documents!\")\n",
    "print(\"\\nFiles created in 'documents' folder:\")\n",
    "print(\"1. python_basics.txt\")\n",
    "print(\"2. ai_intro.txt\")\n",
    "print(\"3. company_policy.txt\")\n",
    "print(\"4. product_info.txt\")\n",
    "\n",
    "# List files to verify\n",
    "files = os.listdir(\"documents\")\n",
    "print(f\"\\nTotal files: {len(files)}\")\n",
    "for file in files:\n",
    "    size = os.path.getsize(f\"documents/{file}\")\n",
    "    print(f\"  - {file} ({size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21841da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: sk-proj-2D_k1B8OV3MW...\n",
      "‚úì Loaded 2 documents and created embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set your OpenAI API key\n",
    "load_dotenv()\n",
    "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\")[:20] + \"...\")\n",
    "\n",
    "# 1. Load documents from folder\n",
    "def load_documents(folder_path):\n",
    "    txt_loader = DirectoryLoader(folder_path, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "    txt_docs = txt_loader.load()\n",
    "    return txt_docs\n",
    "\n",
    "# 2. Create embeddings and save to FAISS\n",
    "def create_vector_store(documents, save_path=\"faiss_index\"):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(save_path)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# 3. Load existing vector store\n",
    "def load_vector_store(save_path=\"faiss_index\"):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    return vectorstore\n",
    "\n",
    "# 4. Query and generate response (simplified)\n",
    "def query_documents(vectorstore, query):\n",
    "    # Retrieve relevant documents\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # Create context from documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Answer the question based on the following context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Get response from LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return response.content, docs\n",
    "\n",
    "# Load and create vector store\n",
    "folder_path = \"./documents\"\n",
    "documents = load_documents(folder_path)\n",
    "vectorstore = create_vector_store(documents)\n",
    "\n",
    "print(f\"‚úì Loaded {len(documents)} documents and created embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f04ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: Who created Python?\n",
      "‚úÖ Answer: Python was created by Guido van Rossum and was first released in 1991.\n",
      "\n",
      "üìÑ Sources (2 documents):\n",
      "  1. documents/ai_intro.txt\n",
      "  2. documents/company_policy.txt\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ùì Question: What is the remote work policy?\n",
      "‚úÖ Answer: The remote work policy allows employees to work remotely up to 3 days per week. Core hours are set from 10 AM to 3 PM local time, during which all team meetings must be scheduled. Employees are required to use Slack for daily communication and must submit their timesheets every Friday by 5 PM. The company provides a laptop and monitor, along with an internet stipend of $50 per month. For any questions regarding this policy, employees should contact HR.\n",
      "\n",
      "üìÑ Sources (2 documents):\n",
      "  1. documents/company_policy.txt\n",
      "  2. documents/ai_intro.txt\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ùì Question: What is machine learning?\n",
      "‚úÖ Answer: Machine learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to enable machines to improve their performance on a specific task through experience, without being explicitly programmed. It allows systems to learn from data and make predictions or decisions based on that data.\n",
      "\n",
      "üìÑ Sources (2 documents):\n",
      "  1. documents/ai_intro.txt\n",
      "  2. documents/company_policy.txt\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query the documents\n",
    "def ask(question):\n",
    "    answer, sources = query_documents(vectorstore, question)\n",
    "    print(f\"\\n‚ùì Question: {question}\")\n",
    "    print(f\"‚úÖ Answer: {answer}\")\n",
    "    print(f\"\\nüìÑ Sources ({len(sources)} documents):\")\n",
    "    for i, doc in enumerate(sources, 1):\n",
    "        print(f\"  {i}. {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Test queries\n",
    "ask(\"Who created Python?\")\n",
    "ask(\"What is the remote work policy?\")\n",
    "ask(\"What is machine learning?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef4479",
   "metadata": {},
   "source": [
    "# Step 2: Query the documents\n",
    "query = \"What is the main topic of the documents?\"\n",
    "\n",
    "# Load vector store (if already created)\n",
    "# vectorstore = load_vector_store(\"faiss_index\")\n",
    "\n",
    "# Get answer\n",
    "answer, sources = query_documents(vectorstore, query)\n",
    "\n",
    "print(\"Answer:\", answer)\n",
    "print(\"\\nSources:\")\n",
    "for i, doc in enumerate(sources):\n",
    "    print(f\"{i+1}. {doc.metadata.get('source', 'Unknown')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
