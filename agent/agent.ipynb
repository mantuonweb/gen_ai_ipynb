{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7a981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.1.6)\n",
      "Requirement already satisfied: langchain-community in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.2.5)\n",
      "Requirement already satisfied: faiss-cpu in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.13.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (1.2.1)\n",
      "Requirement already satisfied: pypdf in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (6.5.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-openai) (2.14.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (0.5.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai langchain-community langchain-text-splitters langchain-core faiss-cpu python-dotenv pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf9e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mantunigam/WORKSPACE/gen_ai_ipynb/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete\n",
      "API Key: sk-proj-2D_k1B8OV3MW...\n",
      "‚úì Folders created: ./resumes and ./resume_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "print(\"‚úì Setup complete\")\n",
    "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\")[:20] + \"...\")\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(\"./resumes\", exist_ok=True)\n",
    "os.makedirs(\"./resume_db\", exist_ok=True)\n",
    "print(\"‚úì Folders created: ./resumes and ./resume_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef98f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Cleaned up old database\n",
      "‚úì Ready for fresh start\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Remove corrupted database\n",
    "if os.path.exists(\"./resume_db\"):\n",
    "    shutil.rmtree(\"./resume_db\")\n",
    "    print(\"‚úì Cleaned up old database\")\n",
    "\n",
    "# Recreate folder\n",
    "os.makedirs(\"./resume_db\", exist_ok=True)\n",
    "print(\"‚úì Ready for fresh start\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f105eb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings globally\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def ingest_resumes():\n",
    "    \"\"\"Load resumes from ./resumes folder and add to vector database\"\"\"\n",
    "    print(\"üì• Ingesting resumes...\")\n",
    "    \n",
    "    # Load text files\n",
    "    txt_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "    txt_docs = txt_loader.load()\n",
    "    \n",
    "    # Load PDF files\n",
    "    pdf_loader = DirectoryLoader(\"./resumes\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "    \n",
    "    all_docs = txt_docs + pdf_docs\n",
    "    \n",
    "    if not all_docs:\n",
    "        print(\"‚ùå No resumes found in ./resumes folder\")\n",
    "        return\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(all_docs)\n",
    "    \n",
    "    # Check if FAISS index file exists (not just folder)\n",
    "    db_file_exists = os.path.exists(\"./resume_db/index.faiss\")\n",
    "    \n",
    "    if db_file_exists:\n",
    "        # Load existing and add new documents\n",
    "        vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "        vectorstore.add_documents(chunks)\n",
    "        print(f\"‚úì Added {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
    "    else:\n",
    "        # Create new vector store\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "        print(f\"‚úì Created new database with {len(chunks)} chunks from {len(all_docs)} resumes\")\n",
    "    \n",
    "    vectorstore.save_local(\"./resume_db\")\n",
    "    print(\"‚úì Database saved successfully\")\n",
    "\n",
    "\n",
    "def list_resumes():\n",
    "    \"\"\"List all resumes stored in vector database\"\"\"\n",
    "    print(\"üìã Listing resumes...\")\n",
    "    \n",
    "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
    "        print(\"‚ùå No database found. Please ingest resumes first.\")\n",
    "        return\n",
    "    \n",
    "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Get all documents\n",
    "    all_docs = vectorstore.docstore._dict\n",
    "    \n",
    "    # Extract unique sources\n",
    "    sources = set()\n",
    "    for doc in all_docs.values():\n",
    "        if hasattr(doc, 'metadata') and 'source' in doc.metadata:\n",
    "            sources.add(os.path.basename(doc.metadata['source']))\n",
    "    \n",
    "    print(f\"\\n‚úì Found {len(sources)} resumes in database:\")\n",
    "    for i, source in enumerate(sorted(sources), 1):\n",
    "        print(f\"  {i}. {source}\")\n",
    "\n",
    "\n",
    "def search_resumes(skills):\n",
    "    \"\"\"Search resumes by skills and return best matches\"\"\"\n",
    "    print(f\"üîç Searching for candidates with skills: {skills}\")\n",
    "    \n",
    "    if not os.path.exists(\"./resume_db/index.faiss\"):\n",
    "        print(\"‚ùå No database found. Please ingest resumes first.\")\n",
    "        return\n",
    "    \n",
    "    vectorstore = FAISS.load_local(\"./resume_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Search for relevant resume chunks\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    docs = retriever.invoke(skills)\n",
    "    \n",
    "    # Create context from retrieved documents\n",
    "    context = \"\\n\\n\".join([f\"Resume {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
    "    \n",
    "    # Create prompt for LLM\n",
    "    prompt = f\"\"\"You are a recruiter assistant. Based on the following resume excerpts, identify and rank the best candidates for the required skills.\n",
    "\n",
    "Required Skills: {skills}\n",
    "\n",
    "Resume Excerpts:\n",
    "{context}\n",
    "\n",
    "Please provide:\n",
    "1. Top 3 best matching candidates\n",
    "2. Their relevant skills and experience\n",
    "3. Why they are a good fit\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Get LLM response\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ SEARCH RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(response.content)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "\n",
    "def clear_resumes():\n",
    "    \"\"\"Clear all resumes from vector database\"\"\"\n",
    "    print(\"üóëÔ∏è  Clearing resume database...\")\n",
    "    \n",
    "    if os.path.exists(\"./resume_db\"):\n",
    "        shutil.rmtree(\"./resume_db\")\n",
    "        print(\"‚úì Database cleared successfully\")\n",
    "    else:\n",
    "        print(\"‚ùå No database found\")\n",
    "\n",
    "print(\"‚úì Agent functions loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113105d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Ingesting resumes...\n",
      "‚úì Created new database with 2 chunks from 2 resumes\n",
      "‚úì Database saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Add resumes to database\n",
    "ingest_resumes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fde6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for candidates with skills: Python, Machine Learning, LangChain\n",
      "\n",
      "============================================================\n",
      "üéØ SEARCH RESULTS\n",
      "============================================================\n",
      "Based on the provided resume excerpts and the required skills of Python, Machine Learning, and LangChain, here are the top candidates ranked by their relevance to the required skills:\n",
      "\n",
      "### 1. Mantu Nigam\n",
      "**Relevant Skills:**\n",
      "- Python\n",
      "- LangChain\n",
      "- Machine Learning (implied through experience with ML models)\n",
      "\n",
      "**Experience:**\n",
      "- **Senior AI Engineer at TechCorp (2021-Present):** Built RAG applications with LangChain and OpenAI, showcasing direct experience with LangChain and Python.\n",
      "- **Software Engineer at DataMinds (2019-2021):** Created ML models and REST APIs with Python, demonstrating proficiency in machine learning.\n",
      "\n",
      "**Why They Are a Good Fit:**\n",
      "Mantu has direct experience with all three required skills. His current role involves using LangChain and Python in a practical application, and he has a solid background in machine learning. This makes him the strongest candidate for the position.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Vinod Malik\n",
      "**Relevant Skills:**\n",
      "- Python\n",
      "- Machine Learning (implied through experience with TensorFlow)\n",
      "\n",
      "**Experience:**\n",
      "- **Full Stack Developer at WebSolutions (2020-Present):** While primarily focused on web development, he has experience with Python and AWS.\n",
      "- **Junior Developer at StartupHub (2019-2020):** Created web interfaces and APIs, but lacks direct experience with LangChain.\n",
      "\n",
      "**Why They Are a Good Fit:**\n",
      "Vinod has Python skills and some exposure to machine learning through TensorFlow. However, he does not have experience with LangChain, which is a critical requirement. He ranks second due to his Python proficiency and potential to learn.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. (No Third Candidate)\n",
      "**Reasoning:**\n",
      "There is no third candidate provided in the excerpts. The only other candidate, Vinod Malik, does not meet the LangChain requirement, which is essential for the role.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary:\n",
      "1. **Mantu Nigam** - Best fit with all required skills.\n",
      "2. **Vinod Malik** - Good fit with Python and machine learning experience but lacks LangChain expertise. \n",
      "\n",
      "Given the specific requirements, Mantu Nigam is the clear choice for the position.\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided resume excerpts and the required skills of Python, Machine Learning, and LangChain, here are the top candidates ranked by their relevance to the required skills:\\n\\n### 1. Mantu Nigam\\n**Relevant Skills:**\\n- Python\\n- LangChain\\n- Machine Learning (implied through experience with ML models)\\n\\n**Experience:**\\n- **Senior AI Engineer at TechCorp (2021-Present):** Built RAG applications with LangChain and OpenAI, showcasing direct experience with LangChain and Python.\\n- **Software Engineer at DataMinds (2019-2021):** Created ML models and REST APIs with Python, demonstrating proficiency in machine learning.\\n\\n**Why They Are a Good Fit:**\\nMantu has direct experience with all three required skills. His current role involves using LangChain and Python in a practical application, and he has a solid background in machine learning. This makes him the strongest candidate for the position.\\n\\n---\\n\\n### 2. Vinod Malik\\n**Relevant Skills:**\\n- Python\\n- Machine Learning (implied through experience with TensorFlow)\\n\\n**Experience:**\\n- **Full Stack Developer at WebSolutions (2020-Present):** While primarily focused on web development, he has experience with Python and AWS.\\n- **Junior Developer at StartupHub (2019-2020):** Created web interfaces and APIs, but lacks direct experience with LangChain.\\n\\n**Why They Are a Good Fit:**\\nVinod has Python skills and some exposure to machine learning through TensorFlow. However, he does not have experience with LangChain, which is a critical requirement. He ranks second due to his Python proficiency and potential to learn.\\n\\n---\\n\\n### 3. (No Third Candidate)\\n**Reasoning:**\\nThere is no third candidate provided in the excerpts. The only other candidate, Vinod Malik, does not meet the LangChain requirement, which is essential for the role.\\n\\n---\\n\\n### Summary:\\n1. **Mantu Nigam** - Best fit with all required skills.\\n2. **Vinod Malik** - Good fit with Python and machine learning experience but lacks LangChain expertise. \\n\\nGiven the specific requirements, Mantu Nigam is the clear choice for the position.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for candidates with specific skills\n",
    "skills = \"Python, Machine Learning, LangChain\"  # Change this to your required skills\n",
    "search_resumes(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84925c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple interactive menu\n",
    "def run_agent():\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìÑ RESUME AGENT - MENU\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1. Ingest Resumes\")\n",
    "        print(\"2. List Resumes\")\n",
    "        print(\"3. Search by Skills\")\n",
    "        print(\"4. Clear Database\")\n",
    "        print(\"5. Exit\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (1-5): \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            ingest_resumes()\n",
    "        elif choice == \"2\":\n",
    "            list_resumes()\n",
    "        elif choice == \"3\":\n",
    "            skills = input(\"Enter required skills (comma-separated): \")\n",
    "            search_resumes(skills)\n",
    "        elif choice == \"4\":\n",
    "            confirm = input(\"Are you sure? (yes/no): \")\n",
    "            if confirm.lower() == \"yes\":\n",
    "                clear_resumes()\n",
    "        elif choice == \"5\":\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice. Please try again.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
